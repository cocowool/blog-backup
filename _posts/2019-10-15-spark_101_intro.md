---
title: Spark学习笔记01-基础
date: 2019-10-15 13:16:17
tag: 
---

目录

* [简介](#简介)
* [特性](#特性)
* [Spark运行模式](#spark运行模式)
* [Mac本地安装](#mac本地安装)


> 本文基于 Spark 2.4.1 进行演示，相关代码可以在我的[Github](Github)上看到。


## 简介
Spark是一个分布式集群计算系统，类似Hadoop提供了强大的分布式计算能力，相比过去的批量处理系统，提供了处理更大规模数据的能力。Spark提供了Java、Python、Scala、R接口。除常见的MapReduce运算外，还支持图、机器学习、SparkSQL等计算方式。

## 特性

* 高效 Speed，因为很多数据都在内存中，相比Hadoop，其处理更为高效。
* 易用 Usability，Spark提供了80多个高级运算符。
* 通用 Generality，提供了大量的库，包括SQL、DataFrames、MLib、GraphX、Spark Streaming。
* 兼容 Runs everywhere，基于jvm能够兼容不同类型的操作系统。

## Spark运行模式

* local : 主要用于开发调试Spark应用程序
* Standlone : 利用Spark自带的资源管理与调度器运行Spark集群，采用Master/Slave结构，为解决单点故障，可以采用Xookeeper实现高可靠(High Availability, HA)
* Apache Mesos : 运行在著名的Mesos资源管理框架基础之上，该集群运行模式将资源管理管理交给Mesos,Spark只负责运行任务调度和计算
* Hadoop YARN : 集群运行在Yarn资源管理器上，资源管理交给YARN，Spark只负责进行任务调度和计算

## Mac本地安装
首先从Spark官方网站下载合适的版本，解压到安装目录，本文使用的是 2.4.1。
配置环境变量```~/.bash_profile```
```bash
export SPARK_HOME=/Users/shiqiang/Projects/tools/spark-2.4.1-bin-hadoop2.7
export PATH=${PATH}:${SPARK_HOME}/bin
```
本机的安装目录
```~/Project/tools```
在Mac系统管理中打开Mac远程登录设置，允许安装用户远程登录。
启动命令
```bash
$ ./sbin/start-all.sh
$ jps
21731 Jps
21717 Worker
21515 Master
```
使用JPS命令可以看到Master和Worker已经启动。也可以单独启动master```./sbin/start-master.sh```，单独启动Worker```./bin/spark-class org.apache.spark.deploy.worker.Worker spark://localhost:7077```

停止服务的方式也非常简单

```bash
$ ./sbin/stop-all.sh
```












